{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Improtantcodesnotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8PJEzwsgNes3R8Cj3SAOt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eildes06/Assigments/blob/main/Improtantcodesnotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Take second item in the list **"
      ],
      "metadata": {
        "id": "qhPh_aJiJUXf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIFF4LKkIxOo"
      },
      "outputs": [],
      "source": [
        "def take_2(x):\n",
        "    if type(x)==float: \n",
        "        return np.nan \n",
        "    else:\n",
        "        return x[1]\n",
        "    \n",
        "# if Nan, return Nan, else take second item in the list     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Take specific item from the list **"
      ],
      "metadata": {
        "id": "EmltnhJjJbHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative def \n",
        "# take a.item from the list\n",
        "def take_list(x,a):\n",
        "    if type(x) == list:\n",
        "        if len(x) > a: \n",
        "            x = x[a]\n",
        "        else:\n",
        "            x = np.nan\n",
        "    else:\n",
        "        x = np.nan\n",
        "    return x"
      ],
      "metadata": {
        "id": "Kwvlv-rgJauv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# usage of def \n",
        "# df['Non-smoking Vehicle'].apply(lambda x: take_list(x,3))"
      ],
      "metadata": {
        "id": "6OjzTDS2Jo5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing value Percentage**"
      ],
      "metadata": {
        "id": "f43MlO6GJJsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # df.isnull().sum()/len(df)*100 #percentage of missing values per columns\n",
        "df.isnull().sum()/df.shape[0]*100"
      ],
      "metadata": {
        "id": "HP-19hLvJG1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**rename**"
      ],
      "metadata": {
        "id": "9ts_57L-Jy-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.rename(columns={'url':'drop_url'},inplace=True)"
      ],
      "metadata": {
        "id": "xuQOTR1OJGxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V6WYmpzTJGmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Model'].isnull().sum()\n",
        "# df['Model'].isna().sum() "
      ],
      "metadata": {
        "id": "bISZFoSjJGjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**clean column**"
      ],
      "metadata": {
        "id": "O0YE3Cm5KBb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative 1\n",
        "df['Model'].apply(lambda x: x[1])"
      ],
      "metadata": {
        "id": "HupVribXKA_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Alternative 2\n",
        "df[\"Model\"].str[1].str.strip(\"\\n\")"
      ],
      "metadata": {
        "id": "xJkXBic5KHSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Alternative 3 - using remove function we created before\n",
        "df['Model'] = df['Model'].apply(take_2)\n",
        "df['Model']"
      ],
      "metadata": {
        "id": "OMOhJmorKHO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Make'] = df['Make'].replace('\\\\n', '', regex=True)\n",
        "df['Make'].value_counts()"
      ],
      "metadata": {
        "id": "o7Hi6Ps_KHLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(np.NaN) # float cikti"
      ],
      "metadata": {
        "id": "bVLyH568KYLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative 1\n",
        "df['Body'].apply(lambda x: np.nan if type(x)==float else x[1])"
      ],
      "metadata": {
        "id": "_FzVChGfKciw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative 2\n",
        "df['Body']=df['Body'].apply(take_2)\n",
        "df['Body']"
      ],
      "metadata": {
        "id": "Z_vogRV2Kcff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[3696] # just checking vat=Nan values on a random row"
      ],
      "metadata": {
        "id": "5TbAF9diKccS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['km'] = df['km'].replace({'[ km]': '', '-': 0 , ',': ''}, regex=True).astype(float).astype('Int64')\n",
        "df['km']"
      ],
      "metadata": {
        "id": "xh3he4iJKtOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['registration']=df['registration'].replace('-/-',np.nan,regex=True)\n",
        "df['registration']"
      ],
      "metadata": {
        "id": "wS88pyK5KtKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['First Registration'] = df[\"First Registration\"].str[1].str.strip(\"\\n\")\n",
        "df['First Registration']"
      ],
      "metadata": {
        "id": "Ywi-RE2rKtHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative \n",
        "df['First Registration'].apply(take_2)"
      ],
      "metadata": {
        "id": "g8BtkAhrK8fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing object to int\n",
        "df['First Registration'] = df['First Registration'].astype(float).astype('Int64')\n",
        "df['First Registration']"
      ],
      "metadata": {
        "id": "1OXH04mdK8b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['prev_owner'] = df['prev_owner'].str.split(\" \").str[0]\n",
        "df['prev_owner']"
      ],
      "metadata": {
        "id": "drd32RUgK8Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Previous Owners\"] = df[\"Previous Owners\"].apply(\n",
        "    lambda x: x[0] if type(x) == list else x).replace('\\\\n', '', regex=True)\n",
        "df[\"Previous Owners\"]"
      ],
      "metadata": {
        "id": "AaY9OjotLIES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['hp']=df['hp'].replace({'[ kW]': '', '-': np.nan}, regex=True).astype('float').astype('Int64')\n",
        "df['hp']"
      ],
      "metadata": {
        "id": "F-RbV9uVLIAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Type_used'] = df['Type'].str[1].str.strip(\"\\n\")\n",
        "df['Type_used']"
      ],
      "metadata": {
        "id": "7RQ3GIlqLH9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Type_fuel']=df['Type'].str[3].str.strip(\"\\n\")\n",
        "df['Type_fuel']"
      ],
      "metadata": {
        "id": "TmI5cy91LS47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fueltype(x):\n",
        "    if x in benzine:\n",
        "        return \"Benzine\"\n",
        "    elif x in lpg:\n",
        "        return \"LPG/CNG\"\n",
        "    else:\n",
        "        return x"
      ],
      "metadata": {
        "id": "5GOoO10WLS1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Type_fuel']=df['Type_fuel'].apply(fueltype)\n",
        "df['Type_fuel']"
      ],
      "metadata": {
        "id": "Xk4MCHvpLSwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Next Inspection Date'] = df['Next Inspection'].apply(\n",
        "    lambda x: np.nan if type(x) == float else x[0]).replace(\"\\\\n\",\"\",regex=True)\n",
        "df['Next Inspection Date']"
      ],
      "metadata": {
        "id": "ixlPV83rLcDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Inspection new(yes/no)\"] = df[\"Inspection new\"].apply(\n",
        "    lambda x: np.nan if type(x) == float else x[0]).replace(\"\\\\\\n\",\"\",regex=True)\n",
        "df[\"Inspection new(yes/no)\"]"
      ],
      "metadata": {
        "id": "5JfguiLsLb_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CO2 Emission'].apply(lambda x: np.nan\n",
        "                         if type(x) == float else x[0]).replace(\n",
        "                             \"\\\\n\", \"\", regex=True).value_counts()"
      ],
      "metadata": {
        "id": "4t0yIU7gLb81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aLternative \n",
        "df[\"CO2 Emission\"] = df[\"CO2 Emission\"].str[0].str.strip(\"\\n\")\n",
        "df[\"CO2 Emission\"]\n",
        "   "
      ],
      "metadata": {
        "id": "vYfZhADqLyT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## if we only want numbers\n",
        "df['CO2 Emission']=df['CO2 Emission'].str.split(\" \").str[0]\n",
        "df['CO2 Emission']"
      ],
      "metadata": {
        "id": "q6dTXikaLyOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Alternative \n",
        "def take_1(x):\n",
        "    if type(x)==float: \n",
        "        return np.nan \n",
        "    elif type(x[0])==list:\n",
        "        return np.nan\n",
        "    else:\n",
        "        return x[0]\n",
        "## if first item is nested list, we won't take it "
      ],
      "metadata": {
        "id": "7qihX1BQL4H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CO2 Emission'].apply(take_1).replace(\"\\\\n\", \"\", regex=True).str.split(\" \").str[0]"
      ],
      "metadata": {
        "id": "cC0SHYzsL4E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Emission_Label_new\"] = df[\"Emission Label\"].str[0].str.split().str[1].str.strip(\"()\")\n",
        "df[\"Emission_Label_new\"]"
      ],
      "metadata": {
        "id": "oXUSStFUL4Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Alternative 1\n",
        "df['Warranty_month'] = df['Warranty'].str[0].str.strip(\"\\n\").str.split(\" \").str[0]\n",
        "df['Warranty_month'] "
      ],
      "metadata": {
        "id": "fLuy1qnFMGwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Alternative 2\n",
        "def take_1(x):\n",
        "    if type(x)==float: \n",
        "        return np.nan \n",
        "    elif type(x[0])==list:\n",
        "        return np.nan\n",
        "    else:\n",
        "          return x[0]"
      ],
      "metadata": {
        "id": "MHng9pj7MGsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ehyshTW_MS2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative def \n",
        "def take_list(x,a):\n",
        "    if type(x) == list:\n",
        "        if len(x) > a:\n",
        "            x = x[a]\n",
        "        else:\n",
        "            x = np.nan\n",
        "    else:\n",
        "        x = np.nan\n",
        "    return x"
      ],
      "metadata": {
        "id": "eFOj6PpqMSzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df['Full Service'].apply(lambda x: take_list(x,2)).replace(\"\\\\n\", \"\", regex=True).value_counts()\n"
      ],
      "metadata": {
        "id": "XwuhWoc5MSv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_smoking_2(x):\n",
        "    if type(x)==float:  # nan value varsa \n",
        "        return np.nan\n",
        "    elif len(x)<3: #  liste icinde 3ten az item varsa\n",
        "        return np.nan\n",
        "    else:\n",
        "        return x[2] # hepsi tutuyorsa bana 3.item getir "
      ],
      "metadata": {
        "id": "RbcUaFDgMh-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Non-smoking Vehicle'].apply(non_smoking_2)"
      ],
      "metadata": {
        "id": "oMtbsDoEMh7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative def \n",
        "def take_list(x,a):\n",
        "    if type(x) == list:\n",
        "        if len(x) > a:\n",
        "            x = x[a]\n",
        "        else:\n",
        "            x = np.nan\n",
        "    else:\n",
        "        x = np.nan\n",
        "    return x"
      ],
      "metadata": {
        "id": "5eNCtKOKMh4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def first_look(col):\n",
        "    print('column name : ', col)\n",
        "    print('--------------------------------')\n",
        "    print('Per_of_Nulls   : ', '%', round(df1[col].isnull().sum() / df1.shape[0]*100, 2))\n",
        "    print('Num_of_Nulls   : ', df1[col].isnull().sum())\n",
        "    print('Num_of_Uniques : ', df1[col].nunique())\n",
        "    print('Duplicates     : ', df1.duplicated(subset = None, keep = 'first').sum())\n",
        "    print(df1[col].value_counts(dropna = False).sort_index())"
      ],
      "metadata": {
        "id": "hsYJ3j86AHkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfn[\"salary_min\"].fillna(value=\"$42K-$76K (Glassdoor est.)\",inplace=True)"
      ],
      "metadata": {
        "id": "Em8o32LdAHaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"SQL\"]=df1[\"job_description\"].str.contains(pat=\"SQL\")"
      ],
      "metadata": {
        "id": "9MfyNsqHBG4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dfc[\"company_name\"] = dfc.company_name.astype(str).str.extract('(\\d{1,4})').astype('float') # str.extract('(\\d+)')"
      ],
      "metadata": {
        "id": "zTY4r1HZCEKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfc.company_name.transform(lambda x: x.str.split(\"\\r\"))"
      ],
      "metadata": {
        "id": "9ViRB1Z1CQKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simdi str[0] bziizm yukardaki liste olurtsurdugumuz her satrin ilk elamanini yazni string kismini getirdi \n",
        "#str[0] disarda calismadiysa icne alabilirsin\n",
        "#sadece index [0] calismadi, ama columun tamamiicin str [0 kullanildi]"
      ],
      "metadata": {
        "id": "yoYYzyrpCaam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfc.company_name.transform(lambda x: x.str.split(\"\\r\")).str[0]\n",
        "#matheww hocanin perfect kodu sondaki onun sihirli argumani imisi\n",
        "#transform apply in ozdesi \n",
        "#apply 3 turlusu var =map, apply, aply map \n",
        "#bunlar arasindan map series ile calisir\n",
        "#aply map dataframe de\n",
        "#apply da ikisinde calisir\n",
        "#apply da grop by yaparsaniz nan deger gelebilir manuel kontrol edilmeli\n",
        "#ya degerler guncellenmeli ya da transform kullanilmali yukardaki durumda\n",
        "#burda apply calismadi calismayinca transform denedik\n",
        "#transform ne olursa ol gel modunda calisir\n",
        "#"
      ],
      "metadata": {
        "id": "x_MwM9dECUX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(df['comfort&convenience'].str.split(',', expand=True).stack().unique())"
      ],
      "metadata": {
        "id": "PsyHZrYCYXL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infos(df, x):\n",
        "    print(\"Column name  :  \"+x)#x den gelen colunm ismi yazdir\n",
        "    print(\"-----------------------------\")# cizgi cizdirir\n",
        "    print(\"Number of nulls  :  \"+str(df[x].isna().sum()))# nullarin toplami \n",
        "    print(\"% of nulls       :  \"+str(round(df[x].isna().sum()/df.shape[0]*100,2))+\"%\")# nullarin data frame orani her sutun icin ortadaki islemi once str ile string yapiyor sonra strin % isareti ekliyor \n",
        "    print(\"Number of uniques:  \"+str(df[x].nunique()))# uniqulerin sayisi hepsi stringdikat butun print ici islemler \n",
        "    print(\"-----------------------------\\nValue Counts\\n\")# value counts larin yazi kismi getirir \n",
        "    print(df[x].value_counts(dropna=False))#valuen counts degerleri getirir \n",
        "  #ekrana print yazmak icin olusturlmus bir fonk, "
      ],
      "metadata": {
        "id": "HrSld6EfijdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sayisal degerler icin :\n",
        "def fill_mean(df, col1, col2, x):#iki columun ort si x ilede doldurmak istedigi column\n",
        "    df[x].fillna(df.groupby([col1,col2])[x].transform(\"mean\"), inplace=True)#x columunu col1,col2 ye gore grupluyor sonra ortalamalrini alip x in bos kisimlari dolduruyor(col1 col2 grupluyor , grup by agregate ister onun icin x yani beliledigimiz columu meani almamaizi transfor ilede uygulatiyor (aplly gibi)\n",
        "    if df[x].isna().sum() != 0:# isna sum ile nullara bakiyor 0 dan farkli ise alttaki kodu calistiriyor.\n",
        "        df[x].fillna(df.groupby(col2)[x].transform(\"mean\"), inplace=True)#colum 2 ye gel x i grupla mean ile x i doldur\n",
        "    print(\"Number of NaN : \",df[x].isna().sum())# columu checkh ediyor x columunda hala null deger var mi diye control ediyor \n",
        "    print(\"------------------\")\n",
        "    print(df[x].value_counts(dropna=False))#doldurduktan sonraki value counts\n",
        "    #apply dataframe ve series uygulanir bazi durumlarda hata verebilir\n",
        "    #map: sadce series de calisir\n",
        "    # apply map: sadece data frame de calsiir\n",
        "    #transform ne olursa ol modunda, data frame ve seriesdde calisir applyin hata verdigi drumlarda bile basarilidir :) "
      ],
      "metadata": {
        "id": "nJk3AZ0ZYY1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#categorik veriler icin tekli gruplama\n",
        "def fill_mode(df, g, f):#bu da tekli gruplama (g bizim gruplayacagimiz colum iken, f de bizim fill edecegimiz icini dolduracagimiz colum)\n",
        "    df[f] = df[f].fillna(df.groupby(g)[f].transform(lambda x: x.mode()[0]))# atama ile ise baslamis cunku burda implace true yok o yzden atama yapip kalici hale getiryoreee, \n",
        "                                                  #dolduracagimiz F columunu  g colmuna gore gruplayip, f deki bos degerleri bu gruplamadiki mod(encok tekrar eden) degeri ile doldurur\n",
        "                                                  #x f deki butun satirlari dolasarak modu buluyor\n",
        "    print(\"Number of NaN :\",df[f].isna().sum())# columu checkh ediyor x columunda hala null deger var mi diye control ediyor \n",
        "    print(\"---------------------\")\n",
        "    print(df[f].value_counts(dropna=False))#doldurduktan sonraki value counts\n"
      ],
      "metadata": {
        "id": "Vccd2xzBinSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#categorik veriler icin ikili gruplama\n",
        "\n",
        "def fill_mode2(df, col1, col2, x):#x dolduracagimiz colum col1 col2 gruplayacagimiz columlar,\n",
        "    for g1 in list(df[col1].unique()):#g1 i col1 iicnde dolastiyor unique degerleri dolasiyor\n",
        "        for g2 in list(df[col2].unique()):#g2 i col2 iicnde dolastiyor unique degerleri dolasiyor\n",
        "            cond1 = df[col1] == g1#burda coolum birden gelen unique degerlerini buluyor ve col1==g1 ise  cond1 e atiyor liste halinde \n",
        "            cond2 = df[col2] == g2#burda coolum birden gelen unique degerlerini buluyor ve col2==g2 ise  cond2 e atiyor liste halinde \n",
        "            try:# dene ki \n",
        "                df.loc[cond1&cond2, x] = df.loc[cond1&cond2, x].fillna(df[cond1&cond2][x].mode()[0])#ilk df ksminda atama yapiyor, \n",
        "                                                                   #ikinci df x i con1 cond2 ye gore grupla bak, \n",
        "                                                                   #filnali kisimda ise cond1 cond2 ye baktin bunlarin bos oldugu yere bunlarin modunu doldur\n",
        "            except:# try de uyguladigin calismaz ise bunu calistir diy0r\n",
        "                df.loc[cond1, x] = df.loc[cond1, x].fillna(df[cond1][x].mode()[0])# ikili gruplama bos ise cond1 ile devam et onun modu ile doldur :) \n",
        "    \n",
        "    print(\"Number of NaN : \",df[x].isna().sum())\n",
        "    print(\"------------------\")\n",
        "    print(df[x].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "jjHX2dgwiXaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datada null degeerleri baska bir serinin verileri dikate alinarak doldurma \n",
        "\n",
        "f.loc[(df[\"Type\"].isna()==True) & (df.km > 100),\"Type\"]= \"Used\" \n",
        "df.loc[(df[\"Type\"].isna()==True) & (df.km < 100),\"Type\"]= \"New\" "
      ],
      "metadata": {
        "id": "ArIK3lbOirt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.dtypes.dtypes import CategoricalDtype\n",
        "df1.describe(percentiles=None, include=None, exclude='category')"
      ],
      "metadata": {
        "id": "GfhYRTt9irqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_nans(df, limit):\n",
        "    missing = df.isnull().sum()*100 / df.shape[0]\n",
        "    return missing.loc[lambda x : x >= limit]\n",
        "def column_nans(serial):\n",
        "    # display percentage of nans in a Series\n",
        "    return serial.isnull().sum()*100 / serial.shape[0]"
      ],
      "metadata": {
        "id": "qDK0krdwirki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(figsize=(4, 10))\n",
        "sns.heatmap(data=df.corr()[['price']].sort_values(by='price'),\n",
        "            vmin = -1, vmax = 1, \n",
        "            annot=True, \n",
        "            cmap='BrBG')"
      ],
      "metadata": {
        "id": "yjPPEWOXe4mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (14,10))\n",
        "sns.heatmap(data=df.corr(), \n",
        "            annot=True, \n",
        "            cmap='Spectral');"
      ],
      "metadata": {
        "id": "AIfOFJyLe4jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.duplicated().sum()\n",
        "df1.astype('object').describe().T"
      ],
      "metadata": {
        "id": "0DRKf19de4f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df[\"Type\"].isna()==True) & (df.km > 100),\"Type\"]= \"Used\" \n",
        "df.loc[(df[\"Type\"].isna()==True) & (df.km < 100),\"Type\"]= \"New\" "
      ],
      "metadata": {
        "id": "buz6xK2dfGNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hp.value_counts().sort_index()\n",
        "#bir aracin beygiri min 60 sayinin ustunde olmali \n",
        "# 60 altinda olamaz o yuzden burda outleier deegerler var"
      ],
      "metadata": {
        "id": "e4o4yZ46fGJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r6akB6XxfGHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DAlYwdz6fGC-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}